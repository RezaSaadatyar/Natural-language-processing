{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Welcome to Natural language processing (NLP) in Python**<br/>\n",
        "\n",
        "Presented by: Reza Saadatyar (2024-2025)<br/>\n",
        "E-mail: Reza.Saadatyar@outlook.com<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outline:<br/>\n",
        "1️⃣ <br/>\n",
        "2️⃣ <br/>\n",
        "3️⃣ <br/>\n",
        "4️⃣ <br/>\n",
        "5️⃣ <br/>\n",
        "6️⃣ <br/>\n",
        "7️⃣ <br/>\n",
        "\n",
        "NLP is a branch of artificial intelligence that allows computers to understand, interpret, and generate human language by combining linguistics, computer science, and machine learning.<br/>\n",
        "\n",
        "**Key Areas of NLP:**<br/>\n",
        "`Text Analysis:`<br/>\n",
        "▪ Tokenization: Breaking text into words or sentences.<br/>\n",
        "▪ Part-of-Speech (POS) Tagging: Identifying grammatical components (e.g., nouns, verbs).<br/>\n",
        "▪ Named Entity Recognition (NER): Extracting entities like names, dates, or organizations.<br/>\n",
        "▪ Sentiment Analysis: Determining the emotional tone (positive, negative, neutral).<br/>\n",
        "\n",
        "`Language Generation:`<br/>\n",
        "▪ Text Summarization: Condensing long texts into shorter summaries.<br/>\n",
        "▪ Machine Translation: Converting text between languages (e.g., Google Translate).<br/>\n",
        "▪ Text Generation: Creating human-like text (e.g., chatbots, story generators).<br/>\n",
        "\n",
        "`Speech Processing:`<br/>\n",
        "▪ Speech Recognition: Converting spoken words to text (e.g., Siri, Alexa).<br/>\n",
        "▪ Text-to-Speech (TTS): Generating spoken language from text.<br/>\n",
        "▪ Voice Assistants: Combining speech recognition and NLP for interactive systems.<br/>\n",
        "\n",
        "`Semantic Understanding:`<br/>\n",
        "▪ Word Embeddings: Representing words as vectors (e.g., Word2Vec, BERT).<br/>\n",
        "▪ Question Answering: Providing precise answers to user queries.<br/>\n",
        "▪ Dialogue Systems: Enabling conversational agents to maintain context.<br/>\n",
        "\n",
        "**Text Word-level Representation (Word Embedding)**<br/>\n",
        "`One-hot Encoding:`<br/>\n",
        "A one-hot encoding transforms categorical variables into binary vectors where each category is represented by a vector with a single '1' and all other positions as '0'. This creates a sparse representation where each category is equidistant from others in vector space.<br/>\n",
        "\n",
        "`Bag-Of-Words (BoW):`<br/>\n",
        "BoW represents text as an unordered collection of words, maintaining word frequency but ignoring grammar and word order. It creates a vocabulary from all unique words and represents each document as a vector of word counts, making it simple but losing contextual relationships.<br/>\n",
        "\n",
        "`Word Embedding:`<br/>\n",
        "Word embeddings map words to dense vectors in a continuous vector space, where semantic relationships are preserved. Words with similar meanings are positioned closer together, enabling the capture of semantic relationships and analogies (e.g., king - man + woman ≈ queen).<br/>\n",
        "\n",
        "`F-IDF (Term Frequency-Inverse Document Frequency):`<br/>\n",
        "TF-IDF measures word importance by considering both:<br/>\n",
        "▪ Term Frequency (TF): How often a word appears in a document<br/>\n",
        "▪ Inverse Document Frequency (IDF): How rare the word is across all documents<br/>\n",
        "This helps identify words that are significant in specific documents but not common across the corpus<br/>\n",
        "\n",
        "`Word2Vec:`<br/>\n",
        "Word2Vec is a neural network-based approach that learns word embeddings by predicting surrounding words (CBOW) or predicting a word from its context (Skip-gram). It captures semantic relationships and can perform tasks like:<br/>\n",
        "▪ Finding similar words<br/>\n",
        "▪ Solving word analogies<br/>\n",
        "▪ Identifying word relationships<br/>\n",
        "▪ Generating word suggestions<br/>\n",
        "\n",
        "**[NLTK](https://www.nltk.org/)**<br/>\n",
        "▪ `Tokenization:` Breaking text into smaller units (words, sentences, or phrases)<br/>\n",
        "▪ `Stemming:` Reducing words to their root form by removing suffixes/prefixes<br/>\n",
        "▪ `Tagging:` Assigning grammatical categories (POS tags) to words<br/>\n",
        "▪ `Parsing:` Analyzing sentence structure and grammatical relationships<br/>\n",
        "▪ `Semantic` Reasoning: Understanding meaning and relationships between words/concepts<br/>\n",
        "▪ `Wrappers:` Interface layers that connect to powerful NLP libraries like spaCy or Stanford NLP<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:#ee0b0b; font-size:20px; font-weight:bold;\">Importing libraries</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install nltk\n",
        "import nltk\n",
        "import nltk.data\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import webtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the Punkt tokenizer models:\n",
        "# - 'punkt': Pre-trained sentence tokenizer model\n",
        "# - 'punkt_tab': Additional tokenizer resources for handling special cases\n",
        "# - 'webtext': Dataset containing diverse text samples for training custom tokenizers\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('webtext')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QYEjg91h9Er",
        "outputId": "9d30b798-fc0c-4670-d2c0-83110500712a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I am learning Natural Language Processing.',\n",
              " 'I am learning Python programming.',\n",
              " 'It is very user friendly.',\n",
              " 'I am ready to start coding.']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "txt = 'I am learning Natural Language Processing. I am learning Python programming. It is very user friendly. I am ready to start coding.'\n",
        "sent_tokenize(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HMmE-6xjkWl_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! Mr reza. How are you today? I can't stand this weather.\n",
            "The sun is too bright and the temperature is unbearable.\n",
            "I don't know how people can work in these conditions.\n",
            "Maybe we should move to a cooler place.\n",
            "What do you think about that?\n"
          ]
        }
      ],
      "source": [
        "# Open a text file using the correct relative path (adjusted for your project structure)\n",
        "txt_file = open(\"D:/Natural-language-processing/Data/sample_text.txt\", mode='r', encoding='utf-8')\n",
        "\n",
        "txt_read = txt_file.read()\n",
        "print(txt_read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eHvSukJmFP1",
        "outputId": "eb5f2781-b851-41c1-e509-5faf1be88311"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "243"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(txt_read) #the number of charachters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUIDOhZ5oyzy",
        "outputId": "a694b8e6-e4ee-4698-eed6-7542d96cda3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hello!',\n",
              " 'Mr reza.',\n",
              " 'How are you today?',\n",
              " \"I can't stand this weather.\",\n",
              " 'The sun is too bright and the temperature is unbearable.',\n",
              " \"I don't know how people can work in these conditions.\",\n",
              " 'Maybe we should move to a cooler place.',\n",
              " 'What do you think about that?']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Punkt_tok = nltk.data.load('nltk:tokenizers/punkt/english.pickle')\n",
        "Punkt_tok.tokenize(txt_read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVoIEU4lpU1w",
        "outputId": "fb3bcd7f-deca-4f01-c4d0-e98c2dfd799b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Punkt_tok.tokenize(txt_read))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXvSLW_8rZfB"
      },
      "source": [
        "Custom Tokenizer Training<br/>\n",
        "We can train our own sentence tokenizer using custom text data. This allows the tokenizer to learn patterns specific to our domain.<br/>\n",
        "\n",
        "[Webtext Corpus](https://paperswithcode.com/dataset/webtext)<br/>\n",
        "The Webtext corpus is a high-quality dataset created by OpenAI through web scraping. It contains diverse text samples that can be used to train robust tokenizers. The corpus emphasizes document quality and natural language patterns.<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72xenMzurigM",
        "outputId": "454c1147-e5be-481e-cf2c-93c2f70c1871"
      },
      "outputs": [],
      "source": [
        "text_parameter = webtext.raw('overheard.txt')\n",
        "# print(text_parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "K6CLD-5wsW6d"
      },
      "outputs": [],
      "source": [
        "#Train my tokenizer\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "My_tokenizer = PunktSentenceTokenizer(text_parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaPhUO8Hsej_",
        "outputId": "b3af1b7e-11cd-4ebb-c8e6-5e3089e1903f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nltk.tokenize.punkt.PunktSentenceTokenizer"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(My_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "C8qhiCQUshUF"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize    # to compare two methods\n",
        "pre_token = sent_tokenize(text_parameter)\n",
        "our_token = My_tokenizer.tokenize(text_parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "T823EuC-sn8T",
        "outputId": "2b87e511-3d25-47a9-c1ea-93587fdf9bb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'White guy: So, do you have any plans for this evening?'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pre_token[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FPxPJp1rsqZ9",
        "outputId": "c7559b53-6b80-4d59-e5cc-c15487baec91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'White guy: So, do you have any plans for this evening?'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "our_token[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_31tlkt7tqXI"
      },
      "source": [
        "##Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaDE-k4jtl1-",
        "outputId": "f01f691c-3642-48df-e127-f67d9bbef77a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'Python',\n",
              " 'programming',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'very',\n",
              " 'user',\n",
              " 'friendly',\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'ready',\n",
              " 'to',\n",
              " 'start',\n",
              " 'coding',\n",
              " '.']"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILUgmBtlty60",
        "outputId": "bc4ca345-87c1-4f7b-8009-5b4b5b2d33cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['do', \"n't\"]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokenize(\"don't\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpfRIeeIuHUF"
      },
      "source": [
        "###TreebankWordTokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4orzDZwbuIyp",
        "outputId": "c312e6f1-32e1-409b-9e1a-53ee51496ae9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hello',\n",
              " '!',\n",
              " 'Mr',\n",
              " 'reza.',\n",
              " 'How',\n",
              " 'are',\n",
              " 'you',\n",
              " 'today',\n",
              " '?',\n",
              " 'I',\n",
              " 'ca',\n",
              " \"n't\",\n",
              " 'stand']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk import TreebankWordTokenizer\n",
        "Tree_Toknizer = TreebankWordTokenizer()  # Create an object\n",
        "Tree_Toknizer.tokenize(\"Hello! Mr reza. How are you today? I can't stand\") # the same problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrZvYVVOuVFD"
      },
      "source": [
        "###WordPunktTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry6vR0zfuTzP",
        "outputId": "fc75569e-bc12-4a69-8bd1-6abc201274fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['can', \"'\", 't']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "Punkt_token = WordPunctTokenizer()\n",
        "Punkt_token.tokenize(\"can't\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Text-Introduction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
