{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-size:16px; font-weight:bold\">Welcome to Natural language processing (NLP) in Python</span><br/>\n",
        "\n",
        "Presented by: Reza Saadatyar (2024-2025)<br/>\n",
        "E-mail: Reza.Saadatyar@outlook.com<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-size: 16px;font-weight:bold\"> One-hot Encoding:</span><br/>\n",
        "One-hot encoding is a technique used in NLP to convert categorical labels into a binary vector format, where only one element is \"1\" (hot) and the others are \"0\".\n",
        "\n",
        "**Steps:**<br/>\n",
        "▪ `Lower-case:` Convert all text to lowercase for uniformity<br/>\n",
        "▪ `Ascending Sorting (A-Z):` Sort unique labels or tokens alphabetically<br/>\n",
        "▪ `Give a Label:` Assign a unique label or token to each category<br/>\n",
        "▪ `Transforming to a Binary Vector:` Convert each label into a binary vector with a single \"1\"<br/>\n",
        "\n",
        "**Implementation:**<br/>\n",
        "1️⃣ `Using NumPy:` Manual one-hot encoding with arrays<br/>\n",
        "2️⃣ `Using Scikit-learn:` Using `OneHotEncoder` for categorical data<br/>\n",
        "3️⃣ `Using TensorFlow:` Integration with neural network pipelines<br/>\n",
        "4️⃣ `Using PyTorch:` Manual and tensor-based encoding<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"dont-size:16.5px; color:rgb(245, 5, 5); font-weight:bold;\">Importing libraries</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-size: 16.5px; font-weight: bold; color:rgb(240, 185, 7)\">1️⃣ Numpy</span><br>\n",
        "\n",
        "**Steps:**<br/>\n",
        "1. Convert text to lowercase<br/>\n",
        "2. Tokenize the text<br/>\n",
        "3. Get unique words <br/>\n",
        "4. Sort the word list<br/>\n",
        "5. Get the integer/position of the words<br/>\n",
        "6. Create a vector of each word by marking its position as 1 and rest as 0<br/>\n",
        "7. Create a matrix of the found vectors<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: i am learning natural language processing.\n",
            "Step 2: ['i', 'am', 'learning', 'natural', 'language', 'processing.']\n",
            "Step 3: ['language', 'i', 'learning', 'processing.', 'am', 'natural']\n",
            "Step 4: ['am' 'i' 'language' 'learning' 'natural' 'processing.']\n",
            "Step 5: {'am': 0, 'i': 1, 'language': 2, 'learning': 3, 'natural': 4, 'processing.': 5}\n",
            "One-hot encoding matrix:\n",
            " [[0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "txt = \"I am learning Natural Language Processing.\"\n",
        "\n",
        "# Step 1: Convert text to lower case\n",
        "txt = txt.lower()\n",
        "print(f\"Step 1: {txt}\")\n",
        "\n",
        "# Step 2: Tokenize the text\n",
        "words = txt.split()\n",
        "print(f\"Step 2: {words}\")\n",
        "\n",
        "# Step 3: Get unique words\n",
        "unique_words = list(set(words))\n",
        "print(f\"Step 3: {unique_words}\")\n",
        "\n",
        "# Step 4: Sort the word list\n",
        "sort = np.sort(unique_words)\n",
        "print(f\"Step 4: {sort}\")\n",
        "\n",
        "# Step 5: Get the integer/position of the words\n",
        "word_to_index = {str(word): index for index, word in enumerate(sort)}\n",
        "print(f\"Step 5: {word_to_index}\")\n",
        "\n",
        "\n",
        "# Step 6: Create a vector of each word by marking its position as 1 and rest as 0\n",
        "vectors = []\n",
        "for word in words:\n",
        "    vector = np.zeros(len(unique_words))\n",
        "    vector[word_to_index[word]] = 1\n",
        "    vectors.append(vector)\n",
        "\n",
        "# Step 7: Create a matrix of the found vectors\n",
        "matrix = np.array(vectors)\n",
        "\n",
        "print(\"One-hot encoding matrix:\\n\", matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-size: 16.5px; font-weight: bold; color:rgb(7, 213, 240)\">3️⃣ Scikit-learn</span><br>\n",
        "\n",
        "**Steps:**<br/>\n",
        "1. Convert text to lowercase<br/>\n",
        "2. Tokenize the text<br/>\n",
        "3. Use LabelEncoder to assign an integer to each unique word<br/>\n",
        "▪  Create a LabelEncoder instance<br/>\n",
        "▪  Fit the LabelEncoder on the list of words to learn the unique words and assign each a unique integer<br/>\n",
        "▪  Transform the list of words into their corresponding integer values (positions)<br/>\n",
        "4. Use OneHotEncoder to create one-hot vectors for each word<br/>\n",
        "▪  Create a OneHotEncoder instance<br/>\n",
        "▪  Reshape the integer labels for compatibility<br/>\n",
        "▪  Fit and transform the integer labels to one-hot vectors<br/>\n",
        "5. Stack the vectors to form a matrix<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: i am learning natural language processing.\n",
            "Step 2: ['i', 'am', 'learning', 'natural', 'language', 'processing.']\n",
            "Word to index mapping: {'am': 0, 'i': 1, 'language': 2, 'learning': 3, 'natural': 4, 'processing.': 5}\n",
            "Step 3: [1 0 3 4 2 5]\n",
            "Step 4:\n",
            " [[0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "txt = \"I am learning Natural Language Processing.\"\n",
        "\n",
        "# Step 1: Convert text to lower case\n",
        "txt = txt.lower()\n",
        "print(f\"Step 1: {txt}\")\n",
        "\n",
        "# Step 2: Tokenize the text\n",
        "words = txt.split()\n",
        "print(f\"Step 2: {words}\")\n",
        "\n",
        "# Step 3: Get its integer value (i.e., the position) by using LabelEncoder()\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(words)\n",
        "word_mapping = {str(word): index for index, word in enumerate(label_encoder.classes_)} # Mapping of words to indices\n",
        "print(\"Word to index mapping:\", word_mapping)\n",
        "print(\"Step 3:\", integer_encoded)\n",
        "\n",
        "# Step 4: Get one hot encoding of the word by referring to the label encoded values using OneHotEncoder()\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "one_hot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(\"Step 4:\\n\", one_hot_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-size:16.5px; color:#45ff54; font-weight:bold\">4️⃣ Keras</span><br/>\n",
        "\n",
        "**Steps:**<br/>\n",
        "1. Convert text to lowercase<br/>\n",
        "2. Tokenize the text (split into words)<br/>\n",
        "3. Assign a unique integer to each unique word<br/>\n",
        "4. Integer encode the sequence of words<br/>\n",
        "5. Use Keras' to_categorical to one-hot encode the integer sequence<br/>\n",
        "6. Stack the one-hot vectors to form a matrix<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: i am learning natural language processing.\n",
            "Step 2: ['i', 'am', 'learning', 'natural', 'language', 'processing.']\n",
            "Step 3: {'am': 0, 'i': 1, 'language': 2, 'learning': 3, 'natural': 4, 'processing.': 5}\n",
            "Step 4: [1, 0, 3, 4, 2, 5]\n",
            "Step 5:\n",
            " [[0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "txt = \"I am learning Natural Language Processing.\"\n",
        "\n",
        "# Step 1: Convert text to lower case\n",
        "txt = txt.lower()\n",
        "print(f\"Step 1: {txt}\")\n",
        "\n",
        "# Step 2: Tokenize the text\n",
        "words = txt.split()\n",
        "print(f\"Step 2: {words}\")\n",
        "\n",
        "# Step 3: Assign a unique integer to each word\n",
        "unique_words = sorted(set(words))\n",
        "word_to_index = {word: idx for idx, word in enumerate(unique_words)}\n",
        "print(\"Step 3:\", word_to_index)\n",
        "\n",
        "# Step 4: Integer encode the sequence\n",
        "sequences = [word_to_index[word] for word in words]\n",
        "print(\"Step 4:\", sequences)\n",
        "\n",
        "# Step 5: One-hot encode using to_categorical\n",
        "vocab_size = len(unique_words)\n",
        "one_hot_encoded = to_categorical(sequences, num_classes=vocab_size)\n",
        "print(\"Step 5:\\n\", one_hot_encoded)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Text-Introduction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
