{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-size:16px; font-weight:bold\">Welcome to Natural language processing (NLP) in Python</span><br/>\n",
        "\n",
        "Presented by: Reza Saadatyar (2024-2025)<br/>\n",
        "E-mail: Reza.Saadatyar@outlook.com<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-size: 16px;font-weight:bold\"> Term Frequency - Inverse Document Frequency (TF-IDF):</span><br/>\n",
        "TF-IDF is a numerical statistic used to evaluate how important a word is to a specific document within a larger collection (corpus).<br/>\n",
        "\n",
        "**TF-IDF combines two metrics:**<br/>\n",
        "▪ `TF:` Measures how frequently a word appears in a document.<br/>\n",
        "▪ `IDF:` Measures how unique or rare a word is across all documents in the corpus.<br/>\n",
        "▪ The TF-IDF value increases when a word appears often in a document but is less common in the rest of the corpus. This helps highlight words that are both frequent and distinctive for a particular document.<br/>\n",
        "▪ TF-IDF is widely used in information retrieval, text mining, and natural language processing tasks such as document classification, search engines (to rank document relevance), and filtering out common words (stop-words).<br/>\n",
        "\n",
        "TF = (Number of times term *t* appears in a document) / (Total number of terms in the document)<br/>\n",
        "IDF = log((Number of documents) / (Number of documents containing term *t*))<br/>\n",
        "TF-IDF = TF × IDF\n",
        "\n",
        "**TF-IDF Workflow:**<br/>\n",
        "▪ `Lowercasing:` Convert all text to lowercase for consistency.<br/>\n",
        "▪ `Tokenization:` Break text into individual words (tokens).<br/>\n",
        "▪ `Vocabulary Building:` Collect all unique words to form the vocabulary.<br/>\n",
        "▪ `Sorting (Optional):` Sort the vocabulary alphabetically for reproducibility.<br/>\n",
        "▪ `Vectorization:` Represent each document as a vector, using TF-IDF scores for each vocabulary word.<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"dont-size:16.5px; color:rgb(245, 5, 5); font-weight:bold;\">Importing libraries</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1:\n",
            "tokenized_docs = [['natural', 'language', 'processing', 'is', 'fascinating'], ['bag', 'of', 'words', 'is', 'a', 'simple', 'model'], ['text', 'data', 'can', 'be', 'represented', 'as', 'vectors'], ['words', 'are', 'important', 'features', 'in', 'nlp']]\n",
            "unique_words = {'a', 'is', 'text', 'nlp', 'bag', 'be', 'are', 'of', 'in', 'natural', 'language', 'processing', 'model', 'data', 'important', 'can', 'represented', 'simple', 'fascinating', 'as', 'features', 'vectors', 'words'}\n",
            "sort_vocab = ['a', 'are', 'as', 'bag', 'be', 'can', 'data', 'fascinating', 'features', 'important', 'in', 'is', 'language', 'model', 'natural', 'nlp', 'of', 'processing', 'represented', 'simple', 'text', 'vectors', 'words']\n",
            "\n",
            "Step 2 (TF):\n",
            "{'a': 0.0, 'are': 0.0, 'as': 0.0, 'bag': 0.0, 'be': 0.0, 'can': 0.0, 'data': 0.0, 'fascinating': 0.2, 'features': 0.0, 'important': 0.0, 'in': 0.0, 'is': 0.2, 'language': 0.2, 'model': 0.0, 'natural': 0.2, 'nlp': 0.0, 'of': 0.0, 'processing': 0.2, 'represented': 0.0, 'simple': 0.0, 'text': 0.0, 'vectors': 0.0, 'words': 0.0}\n",
            "{'a': 0.14285714285714285, 'are': 0.0, 'as': 0.0, 'bag': 0.14285714285714285, 'be': 0.0, 'can': 0.0, 'data': 0.0, 'fascinating': 0.0, 'features': 0.0, 'important': 0.0, 'in': 0.0, 'is': 0.14285714285714285, 'language': 0.0, 'model': 0.14285714285714285, 'natural': 0.0, 'nlp': 0.0, 'of': 0.14285714285714285, 'processing': 0.0, 'represented': 0.0, 'simple': 0.14285714285714285, 'text': 0.0, 'vectors': 0.0, 'words': 0.14285714285714285}\n",
            "{'a': 0.0, 'are': 0.0, 'as': 0.14285714285714285, 'bag': 0.0, 'be': 0.14285714285714285, 'can': 0.14285714285714285, 'data': 0.14285714285714285, 'fascinating': 0.0, 'features': 0.0, 'important': 0.0, 'in': 0.0, 'is': 0.0, 'language': 0.0, 'model': 0.0, 'natural': 0.0, 'nlp': 0.0, 'of': 0.0, 'processing': 0.0, 'represented': 0.14285714285714285, 'simple': 0.0, 'text': 0.14285714285714285, 'vectors': 0.14285714285714285, 'words': 0.0}\n",
            "{'a': 0.0, 'are': 0.16666666666666666, 'as': 0.0, 'bag': 0.0, 'be': 0.0, 'can': 0.0, 'data': 0.0, 'fascinating': 0.0, 'features': 0.16666666666666666, 'important': 0.16666666666666666, 'in': 0.16666666666666666, 'is': 0.0, 'language': 0.0, 'model': 0.0, 'natural': 0.0, 'nlp': 0.16666666666666666, 'of': 0.0, 'processing': 0.0, 'represented': 0.0, 'simple': 0.0, 'text': 0.0, 'vectors': 0.0, 'words': 0.16666666666666666}\n",
            "\n",
            "Step 3 (IDF):\n",
            " {'a': 1.6931471805599454, 'are': 1.6931471805599454, 'as': 1.6931471805599454, 'bag': 1.6931471805599454, 'be': 1.6931471805599454, 'can': 1.6931471805599454, 'data': 1.6931471805599454, 'fascinating': 1.6931471805599454, 'features': 1.6931471805599454, 'important': 1.6931471805599454, 'in': 1.6931471805599454, 'is': 1.2876820724517808, 'language': 1.6931471805599454, 'model': 1.6931471805599454, 'natural': 1.6931471805599454, 'nlp': 1.6931471805599454, 'of': 1.6931471805599454, 'processing': 1.6931471805599454, 'represented': 1.6931471805599454, 'simple': 1.6931471805599454, 'text': 1.6931471805599454, 'vectors': 1.6931471805599454, 'words': 1.2876820724517808}\n",
            "\n",
            "Step 4 (Compute TF-IDF):\n",
            " [{'a': 0.0, 'are': 0.0, 'as': 0.0, 'bag': 0.0, 'be': 0.0, 'can': 0.0, 'data': 0.0, 'fascinating': 0.339, 'features': 0.0, 'important': 0.0, 'in': 0.0, 'is': 0.258, 'language': 0.339, 'model': 0.0, 'natural': 0.339, 'nlp': 0.0, 'of': 0.0, 'processing': 0.339, 'represented': 0.0, 'simple': 0.0, 'text': 0.0, 'vectors': 0.0, 'words': 0.0}, {'a': 0.242, 'are': 0.0, 'as': 0.0, 'bag': 0.242, 'be': 0.0, 'can': 0.0, 'data': 0.0, 'fascinating': 0.0, 'features': 0.0, 'important': 0.0, 'in': 0.0, 'is': 0.184, 'language': 0.0, 'model': 0.242, 'natural': 0.0, 'nlp': 0.0, 'of': 0.242, 'processing': 0.0, 'represented': 0.0, 'simple': 0.242, 'text': 0.0, 'vectors': 0.0, 'words': 0.184}, {'a': 0.0, 'are': 0.0, 'as': 0.242, 'bag': 0.0, 'be': 0.242, 'can': 0.242, 'data': 0.242, 'fascinating': 0.0, 'features': 0.0, 'important': 0.0, 'in': 0.0, 'is': 0.0, 'language': 0.0, 'model': 0.0, 'natural': 0.0, 'nlp': 0.0, 'of': 0.0, 'processing': 0.0, 'represented': 0.242, 'simple': 0.0, 'text': 0.242, 'vectors': 0.242, 'words': 0.0}, {'a': 0.0, 'are': 0.282, 'as': 0.0, 'bag': 0.0, 'be': 0.0, 'can': 0.0, 'data': 0.0, 'fascinating': 0.0, 'features': 0.282, 'important': 0.282, 'in': 0.282, 'is': 0.0, 'language': 0.0, 'model': 0.0, 'natural': 0.0, 'nlp': 0.282, 'of': 0.0, 'processing': 0.0, 'represented': 0.0, 'simple': 0.0, 'text': 0.0, 'vectors': 0.0, 'words': 0.215}]\n",
            "\n",
            "TF-IDF matrix:\n",
            "        a    are     as    bag     be    can   data  fascinating  features  \\\n",
            "0  0.000  0.000  0.000  0.000  0.000  0.000  0.000        0.339     0.000   \n",
            "1  0.242  0.000  0.000  0.242  0.000  0.000  0.000        0.000     0.000   \n",
            "2  0.000  0.000  0.242  0.000  0.242  0.242  0.242        0.000     0.000   \n",
            "3  0.000  0.282  0.000  0.000  0.000  0.000  0.000        0.000     0.282   \n",
            "\n",
            "   important  ...  model  natural    nlp     of  processing  represented  \\\n",
            "0      0.000  ...  0.000    0.339  0.000  0.000       0.339        0.000   \n",
            "1      0.000  ...  0.242    0.000  0.000  0.242       0.000        0.000   \n",
            "2      0.000  ...  0.000    0.000  0.000  0.000       0.000        0.242   \n",
            "3      0.282  ...  0.000    0.000  0.282  0.000       0.000        0.000   \n",
            "\n",
            "   simple   text  vectors  words  \n",
            "0   0.000  0.000    0.000  0.000  \n",
            "1   0.242  0.000    0.000  0.184  \n",
            "2   0.000  0.242    0.242  0.000  \n",
            "3   0.000  0.000    0.000  0.215  \n",
            "\n",
            "[4 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "documents = [\n",
        "    \"Natural language processing is fascinating\",\n",
        "    \"Bag of Words is a simple model\",\n",
        "    \"Text data can be represented as vectors\",\n",
        "    \"Words are important features in NLP\"\n",
        "]\n",
        "\n",
        "# Step 1: Preprocess and build vocabulary\n",
        "tokenized_docs = [doc.lower().split() for doc in documents]  # Tokenize each document by lowercasing and splitting into words\n",
        "unique_words = set(word for doc in tokenized_docs for word in doc)  # Create a set of all unique words from all tokenized documents\n",
        "sort_vocab = sorted(unique_words)  # Sort the unique words alphabetically to form the vocabulary\n",
        "print(f\"Step 1:\\n{tokenized_docs = }\\n{unique_words = }\\n{sort_vocab = }\")\n",
        "\n",
        "# Step 2: Term Frequency (TF)\n",
        "print(f\"\\nStep 2 (TF):\")\n",
        "tf_list = []  # Initialize an empty list to store term frequency dictionaries for each document\n",
        "for doc in tokenized_docs:  # Iterate over each tokenized document\n",
        "    tf = {}  # Initialize an empty dictionary to store term frequencies for the current document\n",
        "    total = len(doc)  # Calculate the total number of words in the current document\n",
        "    for word in sort_vocab:  # Iterate over each word in the sorted vocabulary\n",
        "        tf[word] = doc.count(word) / total  # Compute term frequency for the word and store in the dictionary\n",
        "    tf_list.append(tf)  # Append the term frequency dictionary to the list\n",
        "    print(f\"{tf}\")\n",
        "\n",
        "# Step 3: Compute Inverse Document Frequency (IDF)\n",
        "def compute_idf(tokenized_docs, vocab):  # Define a function to compute IDF values given tokenized documents and vocabulary\n",
        "    N = len(tokenized_docs)  # Number of documents\n",
        "    idf = {}  # Initialize an empty dictionary to store IDF values\n",
        "    for word in vocab:  # Iterate over each word in the vocabulary\n",
        "        doc_count = 0  # Initialize a counter for the number of documents containing the word\n",
        "        for doc in tokenized_docs:  # Iterate over each tokenized document\n",
        "            if word in doc:  # Check if the word is present in the current document\n",
        "                doc_count += 1  # Increment the counter if the word is found in the document\n",
        "        idf[word] = math.log(N / (1 + doc_count)) + 1  # Compute IDF using smoothed formula and store in dictionary\n",
        "    return idf  # Return the dictionary of IDF values\n",
        "\n",
        "idf = compute_idf(tokenized_docs, sort_vocab)\n",
        "print(f\"\\nStep 3 (IDF):\\n {idf}\")\n",
        "\n",
        "# Step 4: Compute TF-IDF\n",
        "tfidf_matrix = []\n",
        "for tf in tf_list:  # Iterate over each term frequency dictionary in the list\n",
        "    tfidf = {}  # Initialize an empty dictionary to store TF-IDF values for the current document\n",
        "    for word in sort_vocab:  # Iterate over each word in the sorted vocabulary\n",
        "        tfidf[word] = round(tf[word] * idf[word], 3)  # Calculate TF-IDF for the word and store in the dictionary\n",
        "    tfidf_matrix.append(tfidf)  # Append the TF-IDF dictionary to the matrix\n",
        "print(f\"\\nStep 4 (Compute TF-IDF):\\n {tfidf_matrix}\")\n",
        "\n",
        "# Step 5: Convert to DataFrame for readability\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix, columns=sort_vocab)\n",
        "print(\"\\nTF-IDF matrix:\\n\", tfidf_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF matrix:\n",
            "         are        as       bag        be       can      data  fascinating  \\\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000     0.465162   \n",
            "1  0.000000  0.000000  0.436719  0.000000  0.000000  0.000000     0.000000   \n",
            "2  0.000000  0.377964  0.000000  0.377964  0.377964  0.377964     0.000000   \n",
            "3  0.421765  0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
            "\n",
            "   features  important        in  ...     model   natural       nlp        of  \\\n",
            "0  0.000000   0.000000  0.000000  ...  0.000000  0.465162  0.000000  0.000000   \n",
            "1  0.000000   0.000000  0.000000  ...  0.436719  0.000000  0.000000  0.436719   \n",
            "2  0.000000   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "3  0.421765   0.421765  0.421765  ...  0.000000  0.000000  0.421765  0.000000   \n",
            "\n",
            "   processing  represented    simple      text   vectors     words  \n",
            "0    0.465162     0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1    0.000000     0.000000  0.436719  0.000000  0.000000  0.344315  \n",
            "2    0.000000     0.377964  0.000000  0.377964  0.377964  0.000000  \n",
            "3    0.000000     0.000000  0.000000  0.000000  0.000000  0.332524  \n",
            "\n",
            "[4 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Create a TfidfVectorizer object\n",
        "# - This object is responsible for converting a list of text documents into a matrix of TF-IDF features.\n",
        "# - It will learn the vocabulary from the documents and calculate the TF-IDF score for each word in each document.\n",
        "# How to calculate TF-IDF?\n",
        "# 1. The vectorizer learns the vocabulary from the documents.\n",
        "# 2. For each word in each document, it computes:\n",
        "#    - Term Frequency (TF): How often the word appears in the document.\n",
        "#    - Inverse Document Frequency (IDF): How unique the word is across all documents.\n",
        "#    - TF-IDF = TF * IDF for each word in each document.\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Step 2: Fit the vectorizer to the documents and transform the documents into TF-IDF vectors\n",
        "# - The 'fit' part learns the vocabulary from the documents.\n",
        "# - The 'transform' part calculates the TF-IDF score for each word in each document.\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Step 3: Retrieve the feature names (i.e., the vocabulary)\n",
        "# This gives us the list of unique words (features) that the vectorizer has learned from the documents.\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the TF-IDF matrix to a dense array and display as a DataFrame for readability\n",
        "import pandas as pd\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "print(\"TF-IDF matrix:\\n\", tfidf_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The two codes above have different outputs because they use different methods and objects to compute the TF-IDF matrix:\n",
        "# \n",
        "# 1. The first code block manually computes TF, IDF, and then TF-IDF using custom logic and stores the results in a DataFrame.\n",
        "#    - The vocabulary is determined by the order in 'sort_vocab'.\n",
        "#    - The calculation and rounding are explicitly controlled.\n",
        "#    - The output DataFrame columns are in the order of 'sort_vocab'.\n",
        "# \n",
        "# 2. The second code block uses scikit-learn's TfidfVectorizer, which:\n",
        "#    - Handles tokenization, normalization, and vocabulary extraction internally.\n",
        "#    - May use different default preprocessing (e.g., lowercasing, token pattern).\n",
        "#    - The vocabulary (feature_names) may be sorted differently (usually alphabetically).\n",
        "#    - The TF-IDF calculation may use slightly different formulas (e.g., smoothing, normalization).\n",
        "#    - The output DataFrame columns are in the order of 'feature_names' as determined by the vectorizer.\n",
        "# \n",
        "# As a result, the two outputs may differ in:\n",
        "# - The order of columns (vocabulary).\n",
        "# - The exact TF-IDF values due to differences in calculation details (e.g., normalization, smoothing).\n",
        "# - The handling of tokenization and preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>are</th>\n",
              "      <th>as</th>\n",
              "      <th>bag</th>\n",
              "      <th>be</th>\n",
              "      <th>can</th>\n",
              "      <th>data</th>\n",
              "      <th>fascinating</th>\n",
              "      <th>features</th>\n",
              "      <th>important</th>\n",
              "      <th>...</th>\n",
              "      <th>model</th>\n",
              "      <th>natural</th>\n",
              "      <th>nlp</th>\n",
              "      <th>of</th>\n",
              "      <th>processing</th>\n",
              "      <th>represented</th>\n",
              "      <th>simple</th>\n",
              "      <th>text</th>\n",
              "      <th>vectors</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.471225</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.471225</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.471225</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.408015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.408015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.408015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.408015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.408015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.289499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.426268</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.426268</td>\n",
              "      <td>0.426268</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.426268</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.302450</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          a       are        as       bag        be       can      data  \\\n",
              "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "1  0.408015  0.000000  0.000000  0.408015  0.000000  0.000000  0.000000   \n",
              "2  0.000000  0.000000  0.377964  0.000000  0.377964  0.377964  0.377964   \n",
              "3  0.000000  0.426268  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "   fascinating  features  important  ...     model   natural       nlp  \\\n",
              "0     0.471225  0.000000   0.000000  ...  0.000000  0.471225  0.000000   \n",
              "1     0.000000  0.000000   0.000000  ...  0.408015  0.000000  0.000000   \n",
              "2     0.000000  0.000000   0.000000  ...  0.000000  0.000000  0.000000   \n",
              "3     0.000000  0.426268   0.426268  ...  0.000000  0.000000  0.426268   \n",
              "\n",
              "         of  processing  represented    simple      text   vectors     words  \n",
              "0  0.000000    0.471225     0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1  0.408015    0.000000     0.000000  0.408015  0.000000  0.000000  0.289499  \n",
              "2  0.000000    0.000000     0.377964  0.000000  0.377964  0.377964  0.000000  \n",
              "3  0.000000    0.000000     0.000000  0.000000  0.000000  0.000000  0.302450  \n",
              "\n",
              "[4 rows x 23 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Manually compute TF, IDF, and TF-IDF as in the first approach\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Build the vocabulary (sorted as in feature_names for comparison)\n",
        "sort_vocab = sorted(set(word for doc in documents for word in doc.lower().split()))\n",
        "\n",
        "# Step 2: Compute Term Frequency (TF)\n",
        "tf = []\n",
        "for doc in documents:\n",
        "    doc_words = doc.lower().split()\n",
        "    doc_tf = []\n",
        "    for word in sort_vocab:\n",
        "        doc_tf.append(doc_words.count(word))\n",
        "    tf.append(doc_tf)\n",
        "tf = np.array(tf)\n",
        "\n",
        "# Step 3: Compute Document Frequency (DF)\n",
        "df = np.sum(tf > 0, axis=0)\n",
        "\n",
        "# Step 4: Compute Inverse Document Frequency (IDF)\n",
        "N = len(documents)\n",
        "idf = np.log((N) / (df)) + 1  # scikit-learn uses \"smooth_idf=True\" by default, but this is the basic formula\n",
        "\n",
        "# Step 5: Compute TF-IDF\n",
        "tfidf_manual = tf * idf\n",
        "\n",
        "# Step 6: Normalize TF-IDF rows to unit norm (L2), as scikit-learn does by default\n",
        "norms = np.linalg.norm(tfidf_manual, axis=1, keepdims=True)\n",
        "tfidf_manual_normalized = tfidf_manual / np.where(norms == 0, 1, norms)\n",
        "\n",
        "# Step 7: Create DataFrame for readability\n",
        "tfidf_manual_df = pd.DataFrame(tfidf_manual_normalized, columns=sort_vocab)\n",
        "tfidf_manual_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              " \twith 24 stored elements and shape (4, 22)>,\n",
              " array(['are', 'as', 'bag', 'be', 'can', 'data', 'fascinating', 'features',\n",
              "        'important', 'in', 'is', 'language', 'model', 'natural', 'nlp',\n",
              "        'of', 'processing', 'represented', 'simple', 'text', 'vectors',\n",
              "        'words'], dtype=object))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_matrix, feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary (sorted): ['a', 'are', 'as', 'bag', 'be', 'can', 'data', 'fascinating', 'features', 'important', 'in', 'is', 'language', 'model', 'natural', 'nlp', 'of', 'processing', 'represented', 'simple', 'text', 'vectors', 'words']\n",
            "Bag of Words matrix:\n",
            " [[0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "txt = [\n",
        "    \"Natural language processing is fascinating\",\n",
        "    \"Bag of Words is a simple model\",\n",
        "    \"Text data can be represented as vectors\",\n",
        "    \"Words are important features in NLP\"\n",
        "]\n",
        "\n",
        "# Step 1 & 2: Create and fit the Tokenizer\n",
        "tok = Tokenizer()\n",
        "tok.fit_on_texts(txt)\n",
        "\n",
        "# Step 3 & 4: Print the sorted vocabulary\n",
        "sorted_vocab = sorted(tok.word_index.keys())\n",
        "print(f'Vocabulary (sorted): {sorted_vocab}')\n",
        "\n",
        "# Step 5: Transform to Bag of Words matrix\n",
        "vectors = tok.texts_to_matrix(txt, mode='count')\n",
        "print(\"Bag of Words matrix:\\n\", vectors)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Text-Introduction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
