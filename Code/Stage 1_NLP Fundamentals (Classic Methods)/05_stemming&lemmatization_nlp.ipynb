{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-size:16px; font-weight:bold\">Welcome to Natural language processing (NLP) in Python</span><br/>\n",
        "\n",
        "Presented by: Reza Saadatyar (2024-2025)<br/>\n",
        "E-mail: Reza.Saadatyar@outlook.com<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"font-size: 16px;font-weight:bold\"> Stemming & Lemmatization:</span><br/>\n",
        "Stemming and Lemmatization are two fundamental techniques in NLP used to reduce words to their root or base forms.<br/>\n",
        "\n",
        "**Stemming:**<br/>\n",
        "▪ Stemming is the process of removing suffixes (and sometimes prefixes) from words to obtain their stem or root form.<br/>\n",
        "▪ The resulting stem may not always be a valid word in the language, but it helps group together words with similar meanings (e.g., \"playing\", \"played\", \"plays\" → \"play\").<br/>\n",
        "▪ Stemming algorithms are typically rule-based and fast, but can be less accurate.<br/>\n",
        "\n",
        "**Lemmatization:**<br/>\n",
        "▪ Lemmatization reduces words to their base or dictionary form, known as the lemma.<br/>\n",
        "▪ Unlike stemming, lemmatization considers the context and part of speech of a word, ensuring that the root form is a valid word (e.g., \"better\" → \"good\", \"running\" → \"run\").<br/>\n",
        "▪ Lemmatization is generally more accurate but may require more computational resources and linguistic knowledge.<br/>\n",
        "\n",
        "**Workflow for Stemming and Lemmatization:**<br/>\n",
        "▪ `Lowercasing:` Convert all text to lowercase for consistency.<br/>\n",
        "▪ `Tokenization:` Split text into individual words (tokens).<br/>\n",
        "▪ `Stemming/Lemmatization:` Apply stemming or lemmatization to each token to obtain root forms.<br/>\n",
        "▪ `Reconstruction (Optional):` Reconstruct the processed tokens back into text for further analysis.<br/>\n",
        "\n",
        "These techniques are commonly used in text preprocessing to normalize words, improve search results, and enhance the performance of NLP models.<br/>\n",
        "\n",
        "**Difference between Stemming and Lemmatization (with Lancaster Stemmer):**<br/>\n",
        "\n",
        "The main difference between stemming and lemmatization is that stemming crudely removes word suffixes to arrive at a root form, which may not be a valid word, while lemmatization reduces words to their dictionary form (lemma), considering context and part of speech.<br/>\n",
        "\n",
        "**Stemming (Lancaster):**<br/>\n",
        "▪ The Lancaster stemmer is more aggressive than the Porter stemmer, often producing shorter stems.<br/>\n",
        "▪ Example: \"playing\", \"played\", \"plays\" → \"play\" (Porter), but Lancaster may reduce further.<br/>\n",
        "\n",
        "**Lemmatization:**<br/>\n",
        "▪ Lemmatization always returns a valid word (lemma) and is context-aware.<br/>\n",
        "▪ Example: \"better\" → \"good\" (with POS), \"running\" → \"run\".<br/>\n",
        "\n",
        "**Comparison Table:**<br/>\n",
        "| Word      | Lancaster Stem | Porter Stem | Lemma      |\n",
        "|-----------|:--------------|:------------|:-----------|\n",
        "| playing   | play           | play        | playing    |\n",
        "| played    | play           | play        | played     |\n",
        "| plays     | play           | play        | play       |\n",
        "| better    | bet            | better      | better     |\n",
        "| running   | run            | run         | running    |\n",
        "\n",
        "The Lancaster stemmer can be too aggressive for some applications, while lemmatization is more accurate but slower.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"dont-size:16.5px; color:rgb(245, 5, 5); font-weight:bold;\">Importing libraries</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, wordpunct_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>tokens</th>\n",
              "      <th>stems</th>\n",
              "      <th>lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cats are running</td>\n",
              "      <td>[cats, are, running]</td>\n",
              "      <td>[cat, are, run]</td>\n",
              "      <td>[cat, are, running]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dogs played outside</td>\n",
              "      <td>[dogs, played, outside]</td>\n",
              "      <td>[dog, play, outsid]</td>\n",
              "      <td>[dog, played, outside]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              original                   tokens                stems  \\\n",
              "0     Cats are running     [cats, are, running]      [cat, are, run]   \n",
              "1  Dogs played outside  [dogs, played, outside]  [dog, play, outsid]   \n",
              "\n",
              "                   lemmas  \n",
              "0     [cat, are, running]  \n",
              "1  [dog, played, outside]  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents = [\n",
        "    \"Cats are running\",\n",
        "    \"Dogs played outside\",\n",
        "]\n",
        "\n",
        "# Initialize stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()  # Create a stemmer object using the Porter algorithm\n",
        "lemmatizer = WordNetLemmatizer() # Create a lemmatizer object using WordNet\n",
        "\n",
        "# Tokenize, Stem, and Lemmatize each document\n",
        "results = []  # Initialize an empty list to store results for each document\n",
        "for doc in documents:  # Iterate over each document in the documents list\n",
        "    tokens = word_tokenize(doc.lower())  # Tokenize the document after converting it to lowercase\n",
        "    stems = [stemmer.stem(token) for token in tokens]  # Apply stemming to each token\n",
        "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]  # Apply lemmatization to each token\n",
        "    results.append({  # Append a dictionary with original text, tokens, stems, and lemmas to the results list\n",
        "        \"original\": doc,  # Store the original document text\n",
        "        \"tokens\": tokens,  # Store the list of tokens\n",
        "        \"stems\": stems,  # Store the list of stemmed tokens\n",
        "        \"lemmas\": lemmas  # Store the list of lemmatized tokens\n",
        "    })\n",
        "\n",
        "# Display results in a DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Stemming vs Lemmatization Comparison:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>stem</th>\n",
              "      <th>lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>playing</td>\n",
              "      <td>play</td>\n",
              "      <td>playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>played</td>\n",
              "      <td>play</td>\n",
              "      <td>played</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plays</td>\n",
              "      <td>play</td>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>better</td>\n",
              "      <td>better</td>\n",
              "      <td>better</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>running</td>\n",
              "      <td>run</td>\n",
              "      <td>running</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      word    stem    lemma\n",
              "0  playing    play  playing\n",
              "1   played    play   played\n",
              "2    plays    play     play\n",
              "3   better  better   better\n",
              "4  running     run  running"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example: Compare stemming and lemmatization for a few words\n",
        "sample_words = [\"playing\", \"played\", \"plays\", \"better\", \"running\", \"feet\"]\n",
        "comparison = []\n",
        "for word in sample_words:\n",
        "    stem = stemmer.stem(word)\n",
        "    lemma = lemmatizer.lemmatize(word)\n",
        "    comparison.append({\"word\": word, \"stem\": stem, \"lemma\": lemma})\n",
        "\n",
        "print(\"\\nStemming vs Lemmatization Comparison:\")\n",
        "df = pd.DataFrame(comparison)\n",
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Text-Introduction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
